{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitazzdev/predict_thainumber/blob/main/brain_tumors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "\n",
        "# Construct the full file path\n",
        "file_path = \"/content/Data\"\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(file_path):\n",
        "    print(f'The file Data exists in the directory.')\n",
        "else:\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Download the Kaggle dataset\n",
        "    !kaggle datasets download -d thomasdubail/brain-tumors-256x256\n",
        "\n",
        "    # Unzip the downloaded dataset\n",
        "    !unzip brain-tumors-256x256.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJR3K7PcrN9l",
        "outputId": "33711cf7-5f78-465a-a624-c8421ade31cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file Data exists in the directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = '1'\n",
        "epochs = 20  # Adjust the number of training epochs\n",
        "learning_rate= 0.01\n",
        "drop_out = 0.7"
      ],
      "metadata": {
        "id": "6x_xomFuwCOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4lqDi8067L6",
        "outputId": "0862c0f1-2881-4645-b8ab-0d08e3ad5605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2479 images belonging to 4 classes.\n",
            "Found 617 images belonging to 4 classes.\n",
            "Found 3096 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define your data directory\n",
        "data_dir = '/content/Data'\n",
        "\n",
        "# Define parameters for data preprocessing\n",
        "image_size = (128, 128)  # Set your desired image size\n",
        "batch_size = 32\n",
        "\n",
        "# Load and preprocess the data\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,          # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,       # Data augmentation: random rotation up to 20 degrees\n",
        "    width_shift_range=0.1,  # Data augmentation: random horizontal shift\n",
        "    height_shift_range=0.1, # Data augmentation: random vertical shift\n",
        "    horizontal_flip=True,    # Data augmentation: random horizontal flip\n",
        "    validation_split=0.2    # Split the data into training and validation\n",
        ")\n",
        "\n",
        "# Load and split the data\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Change this depending on your task\n",
        "    subset='training',         # Specify training data\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Change this depending on your task\n",
        "    subset='validation',       # Specify validation data\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "# You can also use scikit-learn's train_test_split for this\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_generator[0][0], train_generator[0][1], test_size=0.2, random_state=42)\n",
        "\n",
        "# Optionally, you can create a test data generator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Change this depending on your task\n",
        "    shuffle=False,             # No need to shuffle test data\n",
        ")\n",
        "\n",
        "# Now you have training, validation, and test data ready for your CNN model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDvrvqVZBh3B",
        "outputId": "1c85fdc3-09fe-4df6-eb76-ad2b65f979ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 868ms/step - loss: 1.5240 - accuracy: 0.2400 - val_loss: 1.3223 - val_accuracy: 0.3438\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 1.3621 - accuracy: 0.2000 - val_loss: 1.3470 - val_accuracy: 0.3438\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.2745 - accuracy: 0.5200 - val_loss: 1.3025 - val_accuracy: 0.3750\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.2089 - accuracy: 0.4800 - val_loss: 1.2745 - val_accuracy: 0.2812\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3064 - accuracy: 0.5200 - val_loss: 1.3076 - val_accuracy: 0.2188\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 1.1545 - accuracy: 0.7200 - val_loss: 1.2944 - val_accuracy: 0.3438\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 1.1593 - accuracy: 0.4800 - val_loss: 1.2619 - val_accuracy: 0.3438\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.9704 - accuracy: 0.6000 - val_loss: 1.2761 - val_accuracy: 0.3750\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.7534 - accuracy: 0.6400 - val_loss: 1.2914 - val_accuracy: 0.4062\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.8419 - accuracy: 0.6000 - val_loss: 1.2966 - val_accuracy: 0.3125\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.4751 - accuracy: 0.8400 - val_loss: 1.3021 - val_accuracy: 0.4062\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5164 - accuracy: 0.8000 - val_loss: 1.5064 - val_accuracy: 0.3125\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3279 - accuracy: 0.9200 - val_loss: 2.0090 - val_accuracy: 0.4062\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.3327 - accuracy: 0.9200 - val_loss: 1.8015 - val_accuracy: 0.2812\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.3398 - accuracy: 0.9200 - val_loss: 1.6683 - val_accuracy: 0.2812\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.3435 - accuracy: 0.8800 - val_loss: 1.5937 - val_accuracy: 0.4062\n",
            "1/1 - 0s - loss: 1.5629 - accuracy: 0.3438 - 368ms/epoch - 368ms/step\n",
            "Test accuracy: 0.34375\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "num_classes = 4\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))  # Adjust input_shape as per your data\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(drop_out))  # Optional dropout for regularization\n",
        "model.add(Dense(num_classes, activation='softmax'))  # Adjust num_classes for your problem\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate),\n",
        "              loss='categorical_crossentropy',  # Adjust loss function as per your task\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train,  # Your training data\n",
        "    y_train,  # Your training labels\n",
        "    epochs=epochs,\n",
        "    validation_data=(validation_generator[0][0], validation_generator[0][1]),  # Validation data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(\n",
        "    test_generator[0][0], test_generator[0][1], verbose=2)\n",
        "\n",
        "print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "# Make predictions on new data\n",
        "# predictions = model.predict(new_data)  # Replace 'new_data' with your data\n",
        "\n",
        "# Save the model\n",
        "model.save(f'/content/drive/MyDrive/Model/{model_name}.keras')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeZwMmc+U7by5nGQE142o2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}